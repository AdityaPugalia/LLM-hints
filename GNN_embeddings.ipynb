{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Contrastive Learning for Query Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/libpyg.so, 0x0006): tried: '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/libpyg.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/libpyg.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/libpyg.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_scatter/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_cluster/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_spline_conv/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_sparse/_version_cpu.so, 0x0006): tried: '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_sparse/_version_cpu.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_sparse/_version_cpu.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch_sparse/_version_cpu.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader, Dataset\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "from db import Database\n",
    "import config\n",
    "import pandas as pd\n",
    "from qep import Graph\n",
    "import embeddings as emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>select l_returnflag, l_linestatus, sum(l_quant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>select sum(l_extendedprice* (1 - l_discount)) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>select s_name, s_address from supplier, nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select s_name, count(*) as numwait from suppli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select cntrycode, count(*) as numcust, sum(c_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>select p_brand, p_type, p_size, count(distinct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>select sum(l_extendedprice) / 7.0 as avg_yearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>select sum(l_extendedprice* (1 - l_discount)) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>select s_name, s_address from supplier, nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>select cntrycode, count(*) as numcust, sum(c_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                queries\n",
       "0     select l_returnflag, l_linestatus, sum(l_quant...\n",
       "1     select sum(l_extendedprice* (1 - l_discount)) ...\n",
       "2     select s_name, s_address from supplier, nation...\n",
       "3     select s_name, count(*) as numwait from suppli...\n",
       "4     select cntrycode, count(*) as numcust, sum(c_a...\n",
       "...                                                 ...\n",
       "3767  select p_brand, p_type, p_size, count(distinct...\n",
       "3768  select sum(l_extendedprice) / 7.0 as avg_yearl...\n",
       "3769  select sum(l_extendedprice* (1 - l_discount)) ...\n",
       "3770  select s_name, s_address from supplier, nation...\n",
       "3771  select cntrycode, count(*) as numcust, sum(c_a...\n",
       "\n",
       "[3772 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_csv('traindataset/queries_tpch_train.csv', header = 0, names = ['queries'], usecols= [2])\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...hipdate <= date '1998-12-01' - interval '112' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '97' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '79' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...hipdate <= date '1998-12-01' - interval '101' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '69' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '90' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '81' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '62' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...hipdate <= date '1998-12-01' - interval '116' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '82' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...shipdate <= date '1998-12-01' - interval '80' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n",
      "Error executing query: syntax error at or near \"(\"\n",
      "LINE 1: ...hipdate <= date '1998-12-01' - interval '100' day (3) group ...\n",
      "                                                             ^\n",
      "\n",
      "rolling back transaction\n",
      "transaction rolled back\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database(user=config.USER, dbname=config.DBASE)  # Database connection\n",
    "db.connect()  # Connect to the database\n",
    "qtrees = []\n",
    "count = 0\n",
    "for query in queries['queries']:\n",
    "    qtree, _, _, _, error = db.getQep(query)\n",
    "    #filtering out invalid queries from the query set\n",
    "    if error:\n",
    "        continue\n",
    "    G = Graph()\n",
    "    G.parseQep(qtree)\n",
    "    # Create graph features and edge indices\n",
    "    x = torch.tensor(emb.createGraphFeatures(nodes=G.nodes), dtype=torch.float)\n",
    "    edge_index = torch.tensor(G.edges, dtype=torch.long)\n",
    "    qtrees.append(Data(x=x, edge_index=edge_index))\n",
    "    count += 1\n",
    "    if count == 200:\n",
    "        break\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Plan': {'Node Type': 'Aggregate', 'Strategy': 'Plain', 'Partial Mode': 'Finalize', 'Parallel Aware': False, 'Async Capable': False, 'Startup Cost': 41040.96, 'Total Cost': 41040.97, 'Plan Rows': 1, 'Plan Width': 32, 'Plans': [{'Node Type': 'Gather', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Startup Cost': 41040.73, 'Total Cost': 41040.94, 'Plan Rows': 2, 'Plan Width': 32, 'Workers Planned': 2, 'Single Copy': False, 'Plans': [{'Node Type': 'Aggregate', 'Strategy': 'Plain', 'Partial Mode': 'Partial', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Startup Cost': 40040.73, 'Total Cost': 40040.74, 'Plan Rows': 1, 'Plan Width': 32, 'Plans': [{'Node Type': 'Hash Join', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Join Type': 'Inner', 'Startup Cost': 2521.19, 'Total Cost': 40040.66, 'Plan Rows': 10, 'Plan Width': 12, 'Inner Unique': True, 'Hash Cond': '(lineitem.l_partkey = part.p_partkey)', 'Join Filter': '(((part.p_brand = \\'Brand#43\\'::bpchar) AND (part.p_container = ANY (\\'{\"SM CASE\",\"SM BOX\",\"SM PACK\",\"SM PKG\"}\\'::bpchar[])) AND (lineitem.l_quantity >= \\'4\\'::numeric) AND (lineitem.l_quantity <= \\'14\\'::numeric) AND (part.p_size <= 5)) OR ((part.p_brand = \\'Brand#53\\'::bpchar) AND (part.p_container = ANY (\\'{\"MED BAG\",\"MED BOX\",\"MED PKG\",\"MED PACK\"}\\'::bpchar[])) AND (lineitem.l_quantity >= \\'15\\'::numeric) AND (lineitem.l_quantity <= \\'25\\'::numeric) AND (part.p_size <= 10)) OR ((part.p_brand = \\'Brand#32\\'::bpchar) AND (part.p_container = ANY (\\'{\"LG CASE\",\"LG BOX\",\"LG PACK\",\"LG PKG\"}\\'::bpchar[])) AND (lineitem.l_quantity >= \\'27\\'::numeric) AND (lineitem.l_quantity <= \\'37\\'::numeric) AND (part.p_size <= 15)))', 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': True, 'Async Capable': False, 'Relation Name': 'lineitem', 'Alias': 'lineitem', 'Startup Cost': 0.0, 'Total Cost': 37494.61, 'Plan Rows': 9469, 'Plan Width': 21, 'Filter': '((l_shipmode = ANY (\\'{AIR,\"AIR REG\"}\\'::bpchar[])) AND (l_shipinstruct = \\'DELIVER IN PERSON\\'::bpchar) AND (((l_quantity >= \\'4\\'::numeric) AND (l_quantity <= \\'14\\'::numeric)) OR ((l_quantity >= \\'15\\'::numeric) AND (l_quantity <= \\'25\\'::numeric)) OR ((l_quantity >= \\'27\\'::numeric) AND (l_quantity <= \\'37\\'::numeric))))'}, {'Node Type': 'Hash', 'Parent Relationship': 'Inner', 'Parallel Aware': False, 'Async Capable': False, 'Startup Cost': 2520.0, 'Total Cost': 2520.0, 'Plan Rows': 95, 'Plan Width': 30, 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Relation Name': 'part', 'Alias': 'part', 'Startup Cost': 0.0, 'Total Cost': 2520.0, 'Plan Rows': 95, 'Plan Width': 30, 'Filter': '((p_size >= 1) AND (((p_brand = \\'Brand#43\\'::bpchar) AND (p_container = ANY (\\'{\"SM CASE\",\"SM BOX\",\"SM PACK\",\"SM PKG\"}\\'::bpchar[])) AND (p_size <= 5)) OR ((p_brand = \\'Brand#53\\'::bpchar) AND (p_container = ANY (\\'{\"MED BAG\",\"MED BOX\",\"MED PKG\",\"MED PACK\"}\\'::bpchar[])) AND (p_size <= 10)) OR ((p_brand = \\'Brand#32\\'::bpchar) AND (p_container = ANY (\\'{\"LG CASE\",\"LG BOX\",\"LG PACK\",\"LG PKG\"}\\'::bpchar[])) AND (p_size <= 15))))'}]}]}]}]}]}}]\n"
     ]
    }
   ],
   "source": [
    "print(qtrees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTreeDataset(Dataset):\n",
    "    def __init__(self, qtrees, root='', transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        A custom PyTorch Geometric Dataset for storing QEP-based graph data.\n",
    "\n",
    "        Args:\n",
    "            queries (dict): A dictionary containing query strings under `queries['queries']`.\n",
    "            root (str): Root directory for saving/loading the dataset (not used here since it's dynamic).\n",
    "            transform (callable, optional): A function/transform to apply to each graph.\n",
    "            pre_transform (callable, optional): A function/transform to apply before saving the dataset.\n",
    "        \"\"\"\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.qtrees = qtrees\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\"\n",
    "        Returns the number of queries in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.qtrees)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Fetches and parses the QEP for a specific query to generate a graph.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the query.\n",
    "\n",
    "        Returns:\n",
    "            torch_geometric.data.Data: A graph object representing the QEP.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.qtrees[idx]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GNN model\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # Global mean pooling to get a graph-level representation\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCE Loss\n",
    "\n",
    "For a given sample \\(i\\), the loss is defined as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_i = -\\log \\frac{\\exp(\\text{sim}(z_1[i], z_2[i]) / \\tau)}{\\sum_{j=1}^{N} \\exp(\\text{sim}(z_1[i], z_2[j]) / \\tau)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $( \\text{sim}(z_1[i], z_2[j])) $: Similarity between embeddings $( z_1[i] )$ and $( z_2[j] )$ (e.g., cosine similarity or dot product).\n",
    "- $( \\tau )$: Temperature parameter controlling the sharpness of the distribution.\n",
    "- $( N )$: Number of samples in the batch.\n",
    "\n",
    "The total loss across the batch is averaged:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    z1 = F.normalize(z1, p=2, dim=1)\n",
    "    z2 = F.normalize(z2, p=2, dim=1)\n",
    "    similarity_matrix = torch.mm(z1, z2.t()) / temperature\n",
    "    positive_sim = torch.diag(similarity_matrix)\n",
    "    negative_sim = torch.exp(similarity_matrix).sum(dim=1) - torch.exp(positive_sim)\n",
    "    loss = -torch.log(torch.exp(positive_sim) / negative_sim + 1e-8).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_node_features(data, device, mask_prob=0.3):\n",
    "    \"\"\"\n",
    "    Masks random features in the node feature matrix by setting them to zero.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): A graph data object with `data.x` as the node feature matrix.\n",
    "        mask_prob (float): The probability of masking each feature (default is 0.1).\n",
    "\n",
    "    Returns:\n",
    "        torch_geometric.data.Data: A graph data object with masked node features.\n",
    "    \"\"\"\n",
    "    x = data.x  # Node feature matrix (shape: [num_nodes, num_features])\n",
    "    # Create a random mask with the same shape as the feature matrix\n",
    "    mask = torch.rand(x.shape) > mask_prob\n",
    "    mask = mask.to(device)\n",
    "    # Apply the mask (features with a mask value of False are set to 0)\n",
    "    x = x * mask.float()\n",
    "    # Update the graph's feature matrix with the masked features\n",
    "    data.x = x\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        print(data.x.shape)\n",
    "        # Generate two augmented views\n",
    "        view1 = mask_node_features(data, device)\n",
    "        view2 = mask_node_features(data, device)\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "        # Get embeddings\n",
    "        z1 = model(view1.x, view1.edge_index, view1.batch)\n",
    "        z2 = model(view2.x, view2.edge_index, view2.batch)\n",
    "        # Compute contrastive loss\n",
    "        loss = contrastive_loss(z1, z2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([370, 2307])\n",
      "torch.Size([386, 2307])\n",
      "torch.Size([465, 2307])\n",
      "torch.Size([387, 2307])\n",
      "torch.Size([367, 2307])\n",
      "torch.Size([390, 2307])\n",
      "torch.Size([119, 2307])\n",
      "Epoch 1/50, Loss: 3.2071\n",
      "torch.Size([421, 2307])\n",
      "torch.Size([392, 2307])\n",
      "torch.Size([353, 2307])\n",
      "torch.Size([424, 2307])\n",
      "torch.Size([366, 2307])\n",
      "torch.Size([425, 2307])\n",
      "torch.Size([103, 2307])\n",
      "Epoch 2/50, Loss: 3.2212\n",
      "torch.Size([346, 2307])\n",
      "torch.Size([398, 2307])\n",
      "torch.Size([427, 2307])\n",
      "torch.Size([371, 2307])\n",
      "torch.Size([429, 2307])\n",
      "torch.Size([417, 2307])\n",
      "torch.Size([96, 2307])\n",
      "Epoch 3/50, Loss: 3.2208\n",
      "torch.Size([392, 2307])\n",
      "torch.Size([346, 2307])\n",
      "torch.Size([345, 2307])\n",
      "torch.Size([441, 2307])\n",
      "torch.Size([438, 2307])\n",
      "torch.Size([426, 2307])\n",
      "torch.Size([96, 2307])\n",
      "Epoch 4/50, Loss: 3.2212\n",
      "torch.Size([407, 2307])\n",
      "torch.Size([450, 2307])\n",
      "torch.Size([386, 2307])\n",
      "torch.Size([420, 2307])\n",
      "torch.Size([430, 2307])\n",
      "torch.Size([312, 2307])\n",
      "torch.Size([79, 2307])\n",
      "Epoch 5/50, Loss: 3.2213\n",
      "torch.Size([439, 2307])\n",
      "torch.Size([381, 2307])\n",
      "torch.Size([416, 2307])\n",
      "torch.Size([363, 2307])\n",
      "torch.Size([398, 2307])\n",
      "torch.Size([395, 2307])\n",
      "torch.Size([92, 2307])\n",
      "Epoch 6/50, Loss: 3.2213\n",
      "torch.Size([384, 2307])\n",
      "torch.Size([355, 2307])\n",
      "torch.Size([398, 2307])\n",
      "torch.Size([444, 2307])\n",
      "torch.Size([376, 2307])\n",
      "torch.Size([444, 2307])\n",
      "torch.Size([83, 2307])\n",
      "Epoch 7/50, Loss: 3.2213\n",
      "torch.Size([364, 2307])\n",
      "torch.Size([427, 2307])\n",
      "torch.Size([424, 2307])\n",
      "torch.Size([338, 2307])\n",
      "torch.Size([385, 2307])\n",
      "torch.Size([421, 2307])\n",
      "torch.Size([125, 2307])\n",
      "Epoch 8/50, Loss: 3.2214\n",
      "torch.Size([397, 2307])\n",
      "torch.Size([366, 2307])\n",
      "torch.Size([418, 2307])\n",
      "torch.Size([436, 2307])\n",
      "torch.Size([344, 2307])\n",
      "torch.Size([408, 2307])\n",
      "torch.Size([115, 2307])\n",
      "Epoch 9/50, Loss: 3.2214\n",
      "torch.Size([364, 2307])\n",
      "torch.Size([360, 2307])\n",
      "torch.Size([416, 2307])\n",
      "torch.Size([427, 2307])\n",
      "torch.Size([375, 2307])\n",
      "torch.Size([433, 2307])\n",
      "torch.Size([109, 2307])\n",
      "Epoch 10/50, Loss: 3.2214\n",
      "torch.Size([398, 2307])\n",
      "torch.Size([364, 2307])\n",
      "torch.Size([377, 2307])\n",
      "torch.Size([440, 2307])\n",
      "torch.Size([434, 2307])\n",
      "torch.Size([366, 2307])\n",
      "torch.Size([105, 2307])\n",
      "Epoch 11/50, Loss: 3.2214\n",
      "torch.Size([365, 2307])\n",
      "torch.Size([397, 2307])\n",
      "torch.Size([355, 2307])\n",
      "torch.Size([433, 2307])\n",
      "torch.Size([396, 2307])\n",
      "torch.Size([435, 2307])\n",
      "torch.Size([103, 2307])\n",
      "Epoch 12/50, Loss: 3.2214\n",
      "torch.Size([371, 2307])\n",
      "torch.Size([385, 2307])\n",
      "torch.Size([368, 2307])\n",
      "torch.Size([466, 2307])\n",
      "torch.Size([386, 2307])\n",
      "torch.Size([370, 2307])\n",
      "torch.Size([138, 2307])\n",
      "Epoch 13/50, Loss: 3.2214\n",
      "torch.Size([463, 2307])\n",
      "torch.Size([409, 2307])\n",
      "torch.Size([406, 2307])\n",
      "torch.Size([384, 2307])\n",
      "torch.Size([384, 2307])\n",
      "torch.Size([376, 2307])\n",
      "torch.Size([62, 2307])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 23\u001b[0m     loss_new \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_new\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/GNNQueryEncoder.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m contrastive_loss(z1, z2)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = 2307  # Adjust based on your graph node features\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "\n",
    "\n",
    "query_data = QueryTreeDataset(qtrees)\n",
    "\n",
    "loader = DataLoader(query_data, batch_size=32, shuffle=True)\n",
    "# Model and optimizer\n",
    "model = GNNEncoder(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training\n",
    "epochs = 50\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    loss_new = train(model, loader, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_new:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'models/GNNQueryEncoder.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
